{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee1c0262",
   "metadata": {},
   "source": [
    "# Load library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "abaec212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.28.1\n"
     ]
    }
   ],
   "source": [
    "import requests # send request to website\n",
    "from bs4 import BeautifulSoup as bs # convert the web content to bs object\n",
    "from bs4 import Comment # search if we are caught by Amazon as a robot\n",
    "from fake_useragent import UserAgent #create fake user agent from different browser\n",
    "import re # regular expression\n",
    "import pandas as pd # output dataframe\n",
    "import numpy as np # fast data manipulation\n",
    "import random # randomly use agent header for sending request\n",
    "import time #If access is denied, sleep 5s and then request again\n",
    "from collections import defaultdict #Used to declare a dictionary with emply \n",
    "print(requests.__version__)\n",
    "import os\n",
    "import csv\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddefe45",
   "metadata": {},
   "source": [
    "# How to create headers for request\n",
    "1. Some Tutorials I used:\n",
    "    - https://www.crummy.com/software/BeautifulSoup/bs4/doc/#comments-and-other-special-strings\n",
    "    - https://www.blog.datahut.co/post/web-scraping-best-practices-tips\n",
    "    - https://stackoverflow.com/questions/63305902/why-cant-i-scrape-amazon-products-by-beautifulsoup\n",
    "    - https://www.digitalocean.com/community/tutorials/scrape-amazon-product-information-beautiful-soup\n",
    "    - https://stackoverflow.com/questions/63615686/how-to-scrape-data-from-amazon-canada\n",
    "    - https://stackoverflow.com/questions/33138937/how-to-find-all-comments-with-beautiful-soup\n",
    "    - https://pypi.org/project/fake-useragent/\n",
    "    - https://github.com/jhnwr/scrape-amazon-reviews/blob/main/review-scraper.py\n",
    "    - https://www.fullstaxx.com/2021/05/23/multipage-scraping-amazon-python/\n",
    "    - https://github.com/sergioteula/python-amazon-paapi\n",
    "    \n",
    "2. Depends on where Amazon location you are scraping, you need to use different headers. The following are just 2 examples:\n",
    "\n",
    "    - For Amazon Canada: you use:\n",
    "\n",
    "    `headers = {\n",
    "        'content-type': 'text/html;charset=UTF-8',\n",
    "        'Accept-Encoding': 'gzip, deflate, sdch',\n",
    "        'Accept-Language': 'en-US,en;q=0.8',\n",
    "        'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36',\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "    }`\n",
    "\n",
    "    - For Amazon Indian, you use:\n",
    "\n",
    "    `headers = {'User-Agent' : 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.89 Safari/537.36'}`\n",
    "\n",
    "    - For Amazon UK, you use:\n",
    "    \n",
    "    `headers = {\n",
    "    'User-Agent':'Mozilla/5.0 (Windows; U; Windows NT 6.0; en-US; rv:1.8.0.8) Gecko/20061025 Firefox/1.5.0.8'}`\n",
    "    \n",
    "    \n",
    "3. Here is a list of User-Agent strings for different browsers: https://www.useragentstring.com/pages/useragentstring.php\n",
    "4. I will use fake-useragent (pip3 install fake-useragent)to generate a list of fake user agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ccfd08",
   "metadata": {},
   "source": [
    "# Fetch data from individual website using a list of fake User Agent to disguise our IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "511a8e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a class to deal with web request and convert it to beautiful soup\n",
    "class get_soup:\n",
    "    header = None\n",
    "    #When the class is initiated, a list of user agent will be generated\n",
    "    '''\n",
    "    There is a pretty useful third-party package called fake-useragent \n",
    "    that provides a nice abstraction layer over user agents: https://pypi.org/project/fake-useragent/\n",
    "\n",
    "    If you don't want to use the local data, you can use the external data source to retrieve the user-agents. \n",
    "    #Set use_external_data to True:\n",
    "    '''\n",
    "    def __init__(self, total_user_agent = 1000):\n",
    "        ua = UserAgent(browsers=[\"chrome\", \"edge\", \"internet explorer\", \"firefox\", \"safari\", \"opera\"])\n",
    "        # I will generate a lsit of fake agent string with total number of total_user_agent\n",
    "        self.user_agent_set = set()\n",
    "        # Set a cap for user_agent_set to prevent endless loop\n",
    "        while(len(self.user_agent_set)<total_user_agent and len(self.user_agent_set) < 4500):\n",
    "            self.user_agent_set.add(ua.random)\n",
    "    '''\n",
    "    Define the function to get contents from each page. \n",
    "    Each header_attempts will use the same header until it is caught by the weg server.\n",
    "    In each header_attempts, we will try request_attempts times to request contents until we get the right contents\n",
    "    '''\n",
    "    def get_individual_soup(self, url, header_attempts = 10, request_attempts = 10):\n",
    "        self.soup = 'No Data Returned'\n",
    "        for _ in range(header_attempts):\n",
    "            request_count = 0\n",
    "            page = ''\n",
    "            notDenied = True\n",
    "            # We want to keep using the same header if that one particular header is working\n",
    "            # We change it unless it is recognized and banned by Web server\n",
    "            if get_soup.header is None:\n",
    "                user_agent = random.choice(list(self.user_agent_set))\n",
    "                get_soup.header = {'content-type': 'text/html;charset=UTF-8',\n",
    "                'Accept-Encoding': 'gzip, deflate, sdch',\n",
    "                'Accept-Language': 'en-US,en;q=0.8',\n",
    "                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "                \"User-Agent\": user_agent}\n",
    "\n",
    "            while page == '' and request_count < request_attempts and notDenied:\n",
    "                try:\n",
    "                    request_count += 1\n",
    "                    page = requests.get(url, headers=get_soup.header, timeout=10)\n",
    "                    self.soup = bs(page.content, \"lxml\")\n",
    "                    '''If the page returns a message like To discuss automated access \n",
    "                        to Amazon data please contact api-services-support@amazon.com.\n",
    "                        We know we are denied access to the web page.\n",
    "                        Or,\n",
    "                        Amazon page blocks you by returning a login page\n",
    "                        In either case, lets try again using different header\n",
    "                    '''\n",
    "                    comments = self.soup.find_all(string=lambda text: isinstance(text, Comment))\n",
    "                    login_page = self.soup.find('a', id = 'createAccountSubmit', class_ = 'a-button-text')                    \n",
    "                    for comment in comments:\n",
    "                        if (\"api-services-support@amazon.com\" in comment) or login_page:\n",
    "                            notDenied = False\n",
    "                            get_soup.header = None\n",
    "                            self.soup = 'No Data Returned'\n",
    "                            break\n",
    "                            \n",
    "                    if (notDenied):\n",
    "                        return self.soup\n",
    "                    #We are caught by Web server as a bot, break this while and try a new header\n",
    "                    break\n",
    "                except:\n",
    "                    get_soup.header = None\n",
    "                    print(\"Connection refused by the server..\")\n",
    "                    print(\"Let me sleep for 5 seconds\")\n",
    "                    time.sleep(5)\n",
    "                    print(\"Now I will use a different header to request data...\")\n",
    "                    #The server does not respond to our request, break this while and try a new header\n",
    "                    break\n",
    "        return self.soup\n",
    "    '''\n",
    "    Customer Reviews, including Product Star Ratings, \n",
    "    help customers to learn more about the product and decide whether it is the right product for them.\n",
    "    To calculate the overall star rating and percentage breakdown by star, we don’t use a simple average. \n",
    "    Instead, our system considers things like how recent a review is and if the reviewer bought the item on Amazon. \n",
    "    It also analyses reviews to verify trustworthiness.\n",
    "    Learn more from\n",
    "    https://www.amazon.co.uk/gp/help/customer/display.html/ref=cm_cr_arp_d_omni_lm_btn?nodeId=G8UYX7LALQC8V9KA'''\n",
    "    #Define a function to get the review of a product on one page only\n",
    "    def get_page_reviews(self, ASIN, soup = None):\n",
    "        reviewlist = []\n",
    "        if soup is not None:\n",
    "            for item in soup.find_all('div', {'data-hook': 'review'}):\n",
    "                try:\n",
    "                    #This is domenstic review\n",
    "                    review = {\n",
    "                                'ASIN': ASIN,\n",
    "                                'product Name': soup.title.text.replace('Amazon.co.uk:Customer reviews:', '').strip(),\n",
    "                                'Review Title': item.find('a', {'data-hook': 'review-title'}).get_text().strip(),\n",
    "                                'Review Rating':  float(item.find('i', {'data-hook': 'review-star-rating'}).get_text().replace('out of 5 stars', '').strip()),\n",
    "                                'Review Body': item.find('span', {'data-hook': 'review-body'}).get_text().strip(),\n",
    "                                'Review Date': item.find('span', {'data-hook': 'review-date'}).get_text().strip(),\n",
    "                                }\n",
    "                except AttributeError:\n",
    "                    #This is international review\n",
    "                    try:\n",
    "                        review = {\n",
    "                                'ASIN': ASIN,\n",
    "                                'product Name': soup.title.text.replace('Amazon.co.uk:Customer reviews:', '').strip(),\n",
    "                                'Review Title': item.find('span', {'data-hook': 'review-title'}).get_text().strip(),\n",
    "                                'Review Rating':  float(item.find('i', {'data-hook': 'cmps-review-star-rating'}).get_text().replace('out of 5 stars', '').strip()),\n",
    "                                'Review Body': item.find('span', {'data-hook': 'review-body'}).get_text().strip(),\n",
    "                                'Review Date': item.find('span', {'data-hook': 'review-date'}).get_text().strip(),\n",
    "                                }\n",
    "                    except:\n",
    "                        #If there is still error, return None\n",
    "                        review = {\n",
    "                                'ASIN': None,\n",
    "                                'product Name': None,\n",
    "                                'Review Title': None,\n",
    "                                'Review Rating': None,\n",
    "                                'Review Body': None,\n",
    "                                'Review Date': None,\n",
    "                                }\n",
    "                reviewlist.append(review)\n",
    "        return reviewlist\n",
    "\n",
    "#Create a class to handle all the file I/O\n",
    "class Review_file_io:\n",
    "    '''\n",
    "    This method is to get the root link for each product\n",
    "    '''\n",
    "    @classmethod\n",
    "    def get_review_link(cls, file_loc):\n",
    "        #Get the review entrance link for all the product items\n",
    "        review_links = {}\n",
    "        with open (file_loc, mode = \"r\") as f:\n",
    "            for link in f:\n",
    "                entry_link = link.strip().split(\",\")[0]\n",
    "                if (not re.search(\"product-reviews/.*/ref\", entry_link)):\n",
    "                    continue\n",
    "                ASIN = re.search(\"product-reviews/.*/ref\", entry_link).group(0).split(\"/\")[1]\n",
    "                '''Need to think this again, this is mainly for empty page loc'''\n",
    "                if re.search(r'&pageNumber=\\d+$', entry_link):\n",
    "                    review_links[ASIN] = entry_link\n",
    "                else:\n",
    "                    review_links[ASIN] = entry_link + \"&pageNumber=\"\n",
    "        return review_links\n",
    "    '''\n",
    "    This method is to get all the reviews on every page of a product\n",
    "    '''\n",
    "    def get_product_reviews(self, file_loc, reviews_loc, empty_page_loc, total_page = 999, header_attempts = 3, request_attempts = 1):\n",
    "        review_links = Review_file_io.get_review_link(file_loc)\n",
    "        mySoup = get_soup()\n",
    "        empty_page = defaultdict(list)\n",
    "        reviews = []\n",
    "        #loop through each page and get reviews on each page\n",
    "        for ASIN, review_link in review_links.items():\n",
    "            for page_number in range(1,total_page):\n",
    "                print(f\"You are on product {ASIN} page {page_number}\")\n",
    "                page_url = f\"{review_link}{page_number}\"\n",
    "                page_soup = mySoup.get_individual_soup(page_url,header_attempts = header_attempts, request_attempts = request_attempts)\n",
    "                '''\n",
    "                There are 3 cases page_soup equals 'No Data Returned'.\n",
    "                1st is when you get caught by Amazon as a bot;\n",
    "                2nd is Amazon returns you a login page\n",
    "                3rd is when our scrapper has tried header_attempts*request_attempts times to reach the page,\n",
    "                    but still got nothing, either rejected or caught by the server;\n",
    "\n",
    "                There are case that you do get the page content from our web scrapper,\n",
    "                but there are no reviews on that page. For example, \n",
    "                1. You get the page, but the page \n",
    "                2. you hit the last review page;\n",
    "                3. the product item just does not have any reviews at all.\n",
    "                '''\n",
    "                if page_soup != 'No Data Returned':\n",
    "                    review = mySoup.get_page_reviews(ASIN, page_soup)\n",
    "                    #There are simply no reviews for this product item, there are 2 things can happen:\n",
    "                    #1st: the review page is just some random page returned by Amazon\n",
    "                    #2nd: the review page is a normal review page but \n",
    "                        #because the page number has gone out of bound, there is simply no review at all\n",
    "                    if not review:\n",
    "                        #this is is to check if the page is a normal review page but the page number is out of boundary\n",
    "                        #The first find is to check if the page still has product title\n",
    "                        #The second find is to check if there is no Previous Page or Next Page button, that means this is it, there is no more reviews to look, break it\n",
    "                        #what is inside this tag is: '←Previous pageNext page→'\n",
    "                        if page_soup.find(\"a\", attrs={\"data-hook\": \"product-link\"}) and not page_soup.find(\"ul\", {'class': 'a-pagination'}):\n",
    "                            break\n",
    "                        continue\n",
    "                        \n",
    "                    reviews.extend(review)\n",
    "\n",
    "                    #if not page_soup.find(\"ul\", {'class': 'a-pagination'}):\n",
    "                        #break\n",
    "                    #Last page is hit, we break the for loop\n",
    "                    if page_soup.find('li', {'class': 'a-disabled a-last'}):\n",
    "                        break\n",
    "                    else:\n",
    "                        continue\n",
    "                #When we failed to get the content for this page, record this page, and go to the next page\n",
    "                else:\n",
    "                    empty_page[ASIN].append(page_url)\n",
    "                    continue\n",
    "        #Save the reviews and empty page link\n",
    "        try:\n",
    "            with open (reviews_loc, mode = \"a\") as f:\n",
    "                csv_columns = ['ASIN', 'product Name', 'Review Title', 'Review Rating', 'Review Body', 'Review Date']\n",
    "                writer = csv.DictWriter(f, fieldnames=csv_columns)\n",
    "                writer.writeheader()\n",
    "                for prod_info in reviews:\n",
    "                    writer.writerow(prod_info)\n",
    "\n",
    "            with open (empty_page_loc, mode = \"a\") as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow(['URLs', 'ASIN'])\n",
    "                for key, page in empty_page.items():\n",
    "                    for link in page:\n",
    "                        writer.writerow([link, key])\n",
    "        except:\n",
    "            print(\"I/O error\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e488d0",
   "metadata": {},
   "source": [
    "# Example how you can iterate through each page to get the item link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73a55da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are on page 200\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 201\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 202\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 203\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 204\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 205\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 206\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 207\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 208\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 209\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 210\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 211\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 212\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 213\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 214\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 215\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 216\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 217\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 218\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 219\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 220\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 221\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 222\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 223\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 224\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 225\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 226\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 227\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 228\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 229\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 230\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 231\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 232\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 233\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 234\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 235\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 236\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 237\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 238\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 239\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 240\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 241\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 242\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 243\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 244\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 245\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 246\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 247\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 248\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n",
      "You are on page 249\n",
      "You are using Mozilla/4.0 (compatible; MSIE 5.5b1; Mac_PowerPC) to retrieve data\n"
     ]
    }
   ],
   "source": [
    "# Get the link for each product in the home page\n",
    "mySoup = get_soup()\n",
    "#Grab the item link from each page and save them in a text file\n",
    "item_link = []\n",
    "# root_url = \"https://www.amazon.ca/s?k=headphones&i=electronics&page=\"\n",
    "# root_url = \"https://www.amazon.in/s?k=headphones&page=\"\n",
    "root_url = \"https://www.amazon.co.uk/s?k=headphones&i=electronics&s=review-rank&page=\"\n",
    "\n",
    "for page_number in range(200,250):\n",
    "    print(f\"You are on page {page_number}\")\n",
    "    home_soup = mySoup.get_individual_soup(root_url+str(page_number),\n",
    "                                          header_attempts = 2, request_attempts = 1)\n",
    "    #If there is nothing return from the website, go to next page\n",
    "    if home_soup != 'No Data Returned':\n",
    "        if (mySoup.header is not None):\n",
    "            print(\"You are using \" + mySoup.header[\"User-Agent\"] + \" to retrieve data\")\n",
    "    else:\n",
    "        print(f\"No data returned. You are using `{mySoup.header}` to retrieve data\")\n",
    "        continue\n",
    "    for link in home_soup.select(\"h2 a.a-link-normal.s-underline-text.s-underline-link-text.s-link-style\"):\n",
    "        item_link.append(link['href'])\n",
    "\n",
    "with open (\"./Dataset/partial items link CA7.txt\", mode = \"wt\") as f:\n",
    "    for link in item_link:\n",
    "        f.write(link+\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df9d9df",
   "metadata": {},
   "source": [
    "# Generate a csv of links to each of those items, the price and the #of reviews From Stu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79880a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate a new soup object\n",
    "mySoup = get_soup()\n",
    "\n",
    "# home_soup = mySoup.get_individual_soup(root_url+str(page_number),\n",
    "#                                           header_attempts = 2, request_attempts = 1)\n",
    "\n",
    "linklist = []\n",
    "duplicates = []\n",
    "Skipped_pages = []\n",
    "for x in range(2,10):\n",
    "    soup = mySoup.get_individual_soup(f'https://www.amazon.co.uk/s?k=heaphones&page={x}',\n",
    "                                          header_attempts = 2, request_attempts = 1)\n",
    "    \n",
    "    #If there is nothing return from the website, go to next page\n",
    "    if soup != 'No Data Returned':\n",
    "        for link in soup.find_all('a', href=True):\n",
    "            href = link['href']\n",
    "            if 'keywords=heaphones' in href:\n",
    "                if 'offer-listing' not in href:\n",
    "                    if '#customerReviews' not in href:\n",
    "                        duplicates.append(href)\n",
    "    else:\n",
    "        print(f\"No data returned. You are using `{mySoup.header}` to retrieve data\")\n",
    "        Skipped_pages.append(x)\n",
    "        continue\n",
    "\n",
    "duplicates = [x.split('/ref')[0] for x in duplicates]\n",
    "duplicates = [x.split('?keywords')[0] for x in duplicates]\n",
    "for i in duplicates:\n",
    "    # Add to the new list\n",
    "    # only if not present\n",
    "    if i not in linklist:\n",
    "        linklist.append(i)\n",
    "\n",
    "finalList = ['https://www.amazon.co.uk' + s for s in linklist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef3125f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "price = []\n",
    "for x in finalList:\n",
    "    soup = mySoup.get_individual_soup(x, header_attempts = 2, request_attempts = 1)\n",
    "    spans = soup.find('span', attrs = {'class' : 'a-price-whole'})\n",
    "    if spans == None:\n",
    "        price.append('')\n",
    "    else:\n",
    "        price.append(spans.text.strip(punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37008e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.amazon.co.uk/Apple-EarPods-with-Lightning-Connector/dp/B01M1EEPOB',\n",
       " 'https://www.amazon.co.uk/Sony-WH-1000XM3-Wireless-Cancelling-Headphones-Black/dp/B07GDR2LYK',\n",
       " 'https://www.amazon.co.uk/Earphones-Blukar-Headphones-Sensitivity-Microphone-Silver/dp/B07QLWMDLC',\n",
       " 'https://www.amazon.co.uk/JVC-HA-L50-B-E-Lightweight-Headphones-Black/dp/B000I2J4S4',\n",
       " 'https://www.amazon.co.uk/Sony-MDR-ZX310AP-Foldable-Headphones-Smartphone-Metallic-Red/dp/B00I3LV3EU',\n",
       " 'https://www.amazon.co.uk/EarFun-Wireless-Bluetooth-Detection-Headphones-Matte-Black/dp/B088H7GMHZ',\n",
       " 'https://www.amazon.co.uk/Sony-MDR-EX15AP-Earphones-Smartphone-Control-Black/dp/B00I3LV1HE',\n",
       " 'https://www.amazon.co.uk/Betron-AX5-Headphones-Microphone-Smartphones-Black-Gold/dp/B0786S43W4',\n",
       " 'https://www.amazon.co.uk/JVC-Headphones-Earphones-Compatible-Samsung-Black/dp/B00ZAT03S0',\n",
       " 'https://www.amazon.co.uk/Isolating-Headphones-Microphone-Lightweight-Earphones/dp/B083J88QRS',\n",
       " 'https://www.amazon.co.uk/OneOdio-Bluetooth-Over-Ear-Headphones/dp/B0828S1TPM',\n",
       " 'https://www.amazon.co.uk/Soundcore-Microphones-Reduction-Waterproof-Earphones-Black/dp/B07SJR6HL3',\n",
       " 'https://www.amazon.co.uk/Bluetooth-Headphones-KVIDIO-Microphone-Lightweight-pink/dp/B09XMJC9BL',\n",
       " 'https://www.amazon.co.uk/Bluetooth-Headphones-Earphones-Cancelling-Waterproof-Black/dp/B09BZ64R7S',\n",
       " 'https://www.amazon.co.uk/Sennheiser-HD-206-Stereo-Headphone/dp/B01N7S0IPR',\n",
       " 'https://www.amazon.co.uk/Wireless-Headphones-Foldable-Headsets-Earbuds-Black-Gold/dp/B07T1KZQV9',\n",
       " 'https://www.amazon.co.uk/Sony-WH-CH710N-Cancelling-Headphones-Assistant-Black/dp/B086LLYK4S',\n",
       " 'https://www.amazon.co.uk/Headphones-Bluetooth-Earphones-Cancelling-Waterproof-Black/dp/B099D925ZD',\n",
       " 'https://www.amazon.co.uk/yobola-Headphones-Waterproof-Earphones-Bluetooth-T2-Pro-White/dp/B08K4Y4RMB',\n",
       " 'https://www.amazon.co.uk/Edifier-W820NB-Hybrid-Cancelling-Headphones-Black/dp/B09FF244QP',\n",
       " 'https://www.amazon.co.uk/Soundcore-Cancelling-Headphones-Multiple-Bluetooth-Black/dp/B08HMWZBXC',\n",
       " 'https://www.amazon.co.uk/Headphone-Microphone-Bluetooth-Compatible-Smartphones/dp/B09HHFM9SH',\n",
       " 'https://www.amazon.co.uk/Betron-Earphones-Headphones-Microphone-Control-Black/dp/B0B6WKHFLS',\n",
       " 'https://www.amazon.co.uk/DOBOPO-Bluetooth-Earphones-Headphones-Waterproof-White/dp/B0B4DH8Q4C',\n",
       " 'https://www.amazon.co.uk/Wireless-Headphones-Playtime-Bluetooth-Foldable-Grey/dp/B08ND51MX8',\n",
       " 'https://www.amazon.co.uk/Bluetooth-Headphone-Microphone-Cancelling-Earphones/dp/B09XVKPGCM',\n",
       " 'https://www.amazon.co.uk/RockPapa-Adjustable-Headphones-Earphones-Headphone-Blue/dp/B0144PY56Q',\n",
       " 'https://www.amazon.co.uk/Bluetooth-Headphones-WorWoder-Memory-Protein-Travelling/dp/B07FS9B5G8',\n",
       " 'https://www.amazon.co.uk/PowerLocus-Bluetooth-Headphones-Headphone-Microphones-Red/dp/B0BLXRQ175',\n",
       " 'https://www.amazon.co.uk/Jabra-Bluetooth-Cancellation-technology-Multipoint-Titanium-Black/dp/B0B8DRY85Q',\n",
       " 'https://www.amazon.co.uk/Sony-MDR-ZX110NA-Overhead-Cancelling-Headphones-Black/dp/B00N3WWM58',\n",
       " 'https://www.amazon.co.uk/headphones-Microphone-Childrens-headsets-Green-black-green/dp/B07HHGP28X',\n",
       " 'https://www.amazon.co.uk/Headphones-Earbuds-HiFi-Audio-Isolating-Compatible-White-PD4/dp/B09W38W7MF',\n",
       " 'https://www.amazon.co.uk/Wireless-Headphones-Waterproof-Bluetooth-Earphones-White/dp/B09Z2WV32Q',\n",
       " 'https://www.amazon.co.uk/Headphones-Bluetooth-Earphones-Waterproof-Cancelling-Black/dp/B099YZTKCK',\n",
       " 'https://www.amazon.co.uk/Bluetooth-Headphones-Immersive-Earphones-Waterproof-Black/dp/B0B4RVBBRG',\n",
       " 'https://www.amazon.co.uk/Soundcore-Cancelling-Headphones-Bluetooth-Comfortable-Black/dp/B09FPCZ318',\n",
       " 'https://www.amazon.co.uk/Headphones-Earphones-Magnetic-Earbuds-Compatible/dp/B07ZNQYB27',\n",
       " 'https://www.amazon.co.uk/JBL-T110-Universal-Headphones-Control-Microphone-black/dp/B01MG62Z5M',\n",
       " 'https://www.amazon.co.uk/Blukar-Headphones-Sensitivity-Microphone-Multifunction-Black-Red/dp/B0B45WHNGL',\n",
       " 'https://www.amazon.co.uk/Earphones-Bluetooth-Headphones-Cancelling-Airp%F0%9D%96%94%F0%9D%96%89%F0%9D%96%98-Wireless-Earbuds/dp/B0BCZFBPSB',\n",
       " 'https://www.amazon.co.uk/Samsung-EHS64-3-5-Earphones-Remote-White/dp/B00GSPGJCE',\n",
       " 'https://www.amazon.co.uk/Betron-Earphones-Headphones-Powerful-Ergonomic-Black/dp/B01M2V05RE',\n",
       " 'https://www.amazon.co.uk/EO-EG920BW-Samsung-Handsfree-Headphone-Packaging-White/dp/B00ZLTBXSS',\n",
       " 'https://www.amazon.co.uk/Roxel-RX110-Lightweight-Headphones-Compatible-White/dp/B081NT4QC4',\n",
       " 'https://www.amazon.co.uk/Wireless-Bluetooth-Headphones-Charging-Waterproof-White/dp/B09NZMKF6W',\n",
       " 'https://www.amazon.co.uk/Bluetooth-Headphones-Rydohi-Lightweight-Black-Orange/dp/B07PCRLTRK',\n",
       " 'https://www.amazon.co.uk/Sony-MDRZX310L-AE-Foldable-Headphones-Metallic-Blue/dp/B00I3LUYNG',\n",
       " 'https://www.amazon.co.uk/Beats-Solo3-Wireless-Ear-Headphones/dp/B07YVXGFLS',\n",
       " 'https://www.amazon.co.uk/Bluetooth-Headphones-Cancelling-Microphone-Waterproof-White/dp/B0BB29LRQM',\n",
       " 'https://www.amazon.co.uk/Headphones-Bluetooth-Canceling-Waterproof-Earphones/dp/B0B2CZ6J51',\n",
       " 'https://www.amazon.co.uk/Tiksounds-headphones-Bluetooth-Waterproof-black/dp/B08LGRK6MT',\n",
       " 'https://www.amazon.co.uk/NXET-Headphone-Universal-Aluminum-Microsoft/dp/B01L00XVHC',\n",
       " 'https://www.amazon.co.uk/PowerLocus-Bluetooth-Over-Ear-Headphones-Wireless-White-Raspberry/dp/B07D3NPVLN',\n",
       " 'https://www.amazon.co.uk/Bluetooth-Headphones-Microphone-Earphones-Cancelling-Black/dp/B0B3X97WW1',\n",
       " 'https://www.amazon.co.uk/Headphones-Motast-Bluetooth-Earphones-Waterproof-New-Model/dp/B083M83HLD',\n",
       " 'https://www.amazon.co.uk/Headphones-Riwbox-XBT-80-Microphone-Black-Gold/dp/B073QV511F',\n",
       " 'https://www.amazon.co.uk/Panasonic-EAH-AZ70WE-K-Cancelling-Bluetooth-Functionality-Black/dp/B089BHKS6S',\n",
       " 'https://www.amazon.co.uk/Headphones-Bluetooth-Cancellation-Waterproof-Earphones-Wireless-Earbuds/dp/B0BMPY3NMM',\n",
       " 'https://www.amazon.co.uk/Genuine-Samsung-Earphones-Tuned-Line/dp/B071S9RFT7',\n",
       " 'https://www.amazon.co.uk/JKSWT-Microphone-Lightweight-Headphones-Compatible-White/dp/B09DY2N94D',\n",
       " 'https://www.amazon.co.uk/RIDER-Earphones-Headphones-Anti-Tangle-Microphone-Black/dp/B092MKW5CR',\n",
       " 'https://www.amazon.co.uk/Headphones-Microphone-earphone-Cancellation-Compatible-White-1pc/dp/B0BTWYHQ5H',\n",
       " 'https://www.amazon.co.uk/UMI-Bluetooth-headphones-earphones-intelligent-GREY/dp/B07N428SG9',\n",
       " 'https://www.amazon.co.uk/RockPapa-Bluetooth-Headphones-Microphone-Childrens-Purple/dp/B07C253NJ1',\n",
       " 'https://www.amazon.co.uk/TOZO-True-Wireless-Headphones-Stereo-Black/dp/B07RGZ5NKS',\n",
       " 'https://www.amazon.co.uk/Sumvision-Wave-RX-Efficiency-Cancellation-Black/dp/B07XRX18ZZ',\n",
       " 'https://www.amazon.co.uk/Headphones-Waterproof-Bluetooth-Earphones-Airp%F0%9D%96%94%F0%9D%96%89%F0%9D%96%98-White/dp/B0BD41NTX4',\n",
       " 'https://www.amazon.co.uk/Wireless-Bluetooth-Headphones-Rydohi-Foldable-Rose-Gold/dp/B07L93FRP7',\n",
       " 'https://www.amazon.co.uk/Sony-MDR-7506-Professional-Headphone-Black/dp/B000AJIF4E',\n",
       " 'https://www.amazon.co.uk/Sony-MDRRF811RK-CEK-RF811-Wireless-Headphones-Black/dp/B00JF3G0R0',\n",
       " 'https://www.amazon.co.uk/PowerLocus-Bluetooth-Headphones-Microphone-Lightweight-Purple-White/dp/B09312D2XL',\n",
       " 'https://www.amazon.co.uk/Earbuds-Headphones-Microphone-Earphones-Interface-4-Pairs/dp/B08B578J1P',\n",
       " 'https://www.amazon.co.uk/Headphones-Earphones-reduction-compatible-20%EF%BC%8CGoogle-TYC-White/dp/B0BMXHJGHK',\n",
       " 'https://www.amazon.co.uk/Beats-Studio3-Wireless-Cancelling-Headphones/dp/B08529BR4Q',\n",
       " 'https://www.amazon.co.uk/Bluetooth-Headphones-Cancelling-Microphone-Waterproof-Black/dp/B09PG3R55D',\n",
       " 'https://www.amazon.co.uk/Wireless-Bluetooth-Headphones-Cancelling-Earphones-White/dp/B09VDLS6KN',\n",
       " 'https://www.amazon.co.uk/Tribit-Bluetooth-Headphones-lightening-Cancelling-Black/dp/B086ZK4X35',\n",
       " 'https://www.amazon.co.uk/Panasonic-RB-HF420BE-K-Bluetooth-Headphones-Wireless-Black/dp/B08F8SQFT8',\n",
       " 'https://www.amazon.co.uk/Betron-Earphones-Headphones-Isolating-Microphone-Gold/dp/B074P5K78Q',\n",
       " 'https://www.amazon.co.uk/Earphones-Headphones-Microphone-Cancellation-Compatible-White-SG/dp/B09Z34JX14',\n",
       " 'https://www.amazon.co.uk/Headphones-Bluetooth-Cancelling-Earphones-Waterproof-Black/dp/B09V4J7Y7Z',\n",
       " 'https://www.amazon.co.uk/JKSWT-Lightweight-Microphone-Headphones-Compatible-White/dp/B0B2W9H7DW',\n",
       " 'https://www.amazon.co.uk/Betron-S2-Bluetooth-Headphones-Earphones-black/dp/B078C6FSN4',\n",
       " 'https://www.amazon.co.uk/Sony-WI-XB400-Extra-Wireless-Headphones-black/dp/B07X1TDTQB',\n",
       " 'https://www.amazon.co.uk/Lightning-Connector-Headphones-Certified-Isolating-1pc/dp/B09TR61Q26',\n",
       " 'https://www.amazon.co.uk/Sony-WH-XB910N-Cancelling-Wireless-Headphones-Black/dp/B09FKG4PP3',\n",
       " 'https://www.amazon.co.uk/DOQAUS-Wireless-Headphones-Bluetooth-Controller-Black/dp/B09FX97PPL',\n",
       " 'https://www.amazon.co.uk/JKSWT-Microphone-Definition-Headphones-Compatible-Black/dp/B0919BBRB2',\n",
       " 'https://www.amazon.co.uk/Sennheiser-Special-Open-Headphone-Black/dp/B07Q7S7247',\n",
       " 'https://www.amazon.co.uk/JVC-HA-S160-B-FLATS-Lightweight-Headphones-Black/dp/B004M7SQNU',\n",
       " 'https://www.amazon.co.uk/IeemTkxxe-Headphones-Earphones-Bluetooth-Cancellation-white/dp/B0B97VTX4Y',\n",
       " 'https://www.amazon.co.uk/Wireless-Bluetooth-Headphones-Earphones-Waterproof-Midnight-Black/dp/B0BFL83X8S',\n",
       " 'https://www.amazon.co.uk/Wireless-Headphones-Bluetooth-Canceling-Waterproof-New-Model/dp/B08JYZ38P7',\n",
       " 'https://www.amazon.co.uk/Betron-AX3-Headphones-Microphone-Smartphones-Black/dp/B0787JJ8J9',\n",
       " 'https://www.amazon.co.uk/Rockpapa-Comfort-Adjustable-Headphones-SmartPhones-Orange-Black/dp/B07DWNPNTC',\n",
       " 'https://www.amazon.co.uk/Urbanista-Bluetooth-Headphones-Cancelling-Microphone-Teal-Green/dp/B08TLV4XYJ',\n",
       " 'https://www.amazon.co.uk/Bluetooth-Headphones-Cancelling-Btootos-Waterproof-Black/dp/B0BCKHQGJN',\n",
       " 'https://www.amazon.co.uk/Earphones-Headphones-Sensitivity-Microphone-Definition-White/dp/B09KX53SGM',\n",
       " 'https://www.amazon.co.uk/Wireless-Certified-Bluetooth-Waterproof-Microphone-White-Wireless/dp/B0BJC4JBV3',\n",
       " 'https://www.amazon.co.uk/Bluetooth-Headphones-Wireless-Waterproof-Earphones-Black/dp/B091GHJ7FN',\n",
       " 'https://www.amazon.co.uk/Betron-Isolating-Headphones-Earphones-Powerful-Black/dp/B00MIQQVIY',\n",
       " 'https://www.amazon.co.uk/Headphones-Bluetooth-Cancellation-Waterproof-Earphones-white/dp/B0BFPQDXSG',\n",
       " 'https://www.amazon.co.uk/New-Headphones-Microphone-Children-Lightweight-Pink/dp/B09H4K1YR6',\n",
       " 'https://www.amazon.co.uk/Bluetooth-Wireless-Headphones-Louise-Mann-Black/dp/B08HRVFF65',\n",
       " 'https://www.amazon.co.uk/ZIHNIC-Bluetooth-Headphones-Over-Ear-Prolonged-rose/dp/B0BFFSRNGL',\n",
       " 'https://www.amazon.co.uk/Headphones-Reduction-bluetooth-earphones-Waterproof/dp/B0BKFXSM6Q',\n",
       " 'https://www.amazon.co.uk/Wireless-Headphones-Playtime-Bluetooth-Cellphone-Type1-Red/dp/B08FMMC1F8',\n",
       " 'https://www.amazon.co.uk/Tijjywwil-Earphones-Headphones-Microphone-Compatible-white/dp/B0B8S1WYZW',\n",
       " 'https://www.amazon.co.uk/Sony-Wireless-Cancelling-Headphones-Compatible-Blue/dp/B07X2T4QYP',\n",
       " 'https://www.amazon.co.uk/Philips-00-Headphones-Bluetooth-Isolation-Black/dp/B08CNM8YPD',\n",
       " 'https://www.amazon.co.uk/GNFROP-Environmental-Cancellation-Cancelling-Headphones-White/dp/B0BJ6Y28HY',\n",
       " 'https://www.amazon.co.uk/Groov-Headphones-Adjustable-Headphone-Smartphones-Pink/dp/B00378KLQK',\n",
       " 'https://www.amazon.co.uk/Sony-WH-CH520-Wireless-Bluetooth-Headphones-Beige/dp/B0BTJ9WHL9',\n",
       " 'https://www.amazon.co.uk/UGREEN-Headphones-Earphones-Earbuds-Compatible/dp/B094Y63W42',\n",
       " 'https://www.amazon.co.uk/Sony-WI-C310-Bluetooth-Wireless-Headphones-Black/dp/B07R37BSZ6',\n",
       " 'https://www.amazon.co.uk/Wireless-Headphones-Bluetooth-Playback-Waterproof-Rose-Gold/dp/B09YC24Q43',\n",
       " 'https://www.amazon.co.uk/ZJXD-Headphones-Microphone-Compatible-Smartphones-White/dp/B07PGD6FBW',\n",
       " 'https://www.amazon.co.uk/Jabra-Evolve2-Wireless-Headset-Long-Lasting-Black/dp/B08633D2K5',\n",
       " 'https://www.amazon.co.uk/C8-Headphones-Microphone-Lightweight-Smartphones-Mint/dp/B01EF5DBYM',\n",
       " 'https://www.amazon.co.uk/Earphones-Headphones-Microphone-Control-Compatible-White-SMA/dp/B0BN33Y2XD',\n",
       " 'https://www.amazon.co.uk/Satily-Earphones-Microphone-Cancelling-Waterproof-Black/dp/B0BTBHC1MM',\n",
       " 'https://www.amazon.co.uk/SONY-WI-C200-Wireless-Bluetooth-Headphones-Black/dp/B07QYWD718',\n",
       " 'https://www.amazon.co.uk/Samsung-Galaxy-Wireless-Earphones-Version/dp/B08C5HYHYB',\n",
       " 'https://www.amazon.co.uk/Bluetooth-Headphones-Playtime-Cancellation-Invisible-Ear/dp/B07YFMK89B']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = []\n",
    "for x in finalList:\n",
    "    soup = mySoup.get_individual_soup(x, header_attempts = 2, request_attempts = 1)\n",
    "    spans = soup.find('span',id =\"acrCustomerReviewText\", attrs = {'class' : 'a-size-base'})\n",
    "    if spans == None:\n",
    "        review.append('')\n",
    "    else:\n",
    "        review.append(spans.text.strip(punctuation))\n",
    "\n",
    "finalList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e5a407b",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['URLs', 'Price', '#Ratings']\n",
    "\n",
    "finalList = [s+ '/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews' for s in finalList]\n",
    "finalList = [s.replace(\"/dp/\", \"/product-reviews/\") for s in finalList]\n",
    "\n",
    "with open('links.csv', 'w', newline='') as csvfile:\n",
    "    file_is_empty = os.stat('links.csv').st_size == 0\n",
    "    writer = csv.writer(csvfile)\n",
    "    if file_is_empty:\n",
    "        writer.writerow(headers)\n",
    "    writer.writerows(zip(finalList, price, review))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed026a3",
   "metadata": {},
   "source": [
    "# Extract product information from multiple product items\n",
    "There are a few product information we can get from a single product item.\n",
    "\n",
    "- Product Name\n",
    "- Review Title\n",
    "- Review Rating\n",
    "- Review Body\n",
    "- Review Date\n",
    "\n",
    "Because each product has many pages of reviews and each product takes quite some time, I split the links.csv file to smaller files. Each file has about 35 links in there, and I will need other team members to work separately to reduce running time. https://phoenixnap.com/kb/linux-split#:~:text=The%20Linux%20split%20command%20breaks,Linux%20split%20command%20with%20examples.&text=Access%20to%20the%20terminal%20line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "c30f5cc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# my_review = Review_file_io()\n",
    "# # my_review.get_review_link('./Dataset/Sample_link.csv')\n",
    "# my_review.get_product_reviews('./Dataset/Yong/best_seller_headphone_link.csv', './Dataset/Yong/best_review.csv', './Dataset/Yong/best_empty_link.csv', total_page = 200,\n",
    "#                              header_attempts=3, request_attempts=1)\n",
    "\n",
    "'''\n",
    "Concatnate multiple csv and remove duplicates, write to a parquet file\n",
    "'''\n",
    "lu_review = pd.read_csv(\"./Dataset/Yong/review2.csv\")\n",
    "total_review = pd.read_parquet(\"./Dataset/AmazonReviews.parquet\")\n",
    "AmazonReviews = pd.concat([total_review, lu_review], ignore_index=True)\n",
    "AmazonReviews.drop_duplicates().astype(str).to_parquet('./Dataset/AmazonReviews2.parquet')\n",
    "\n",
    "#The following is used to get Amazon Product Price informaiton\n",
    "link1 = pd.read_csv(\"./Dataset/links.csv\")\n",
    "link2 = pd.read_csv(\"./Dataset/links2.csv\")\n",
    "link1['ASIN'] = link1.apply(lambda x: re.search(\"product-reviews/.*/ref\", x['URLs']).group(0).split(\"/\")[1], axis=1)\n",
    "link2['ASIN'] = link2.apply(lambda x: re.search(\"product-reviews/.*/ref\", x['URLs']).group(0).split(\"/\")[1], axis=1)\n",
    "AmazonProductPrice = pd.concat([link1, link2], ignore_index=True).drop_duplicates(subset=\"ASIN\")\n",
    "AmazonProductPrice.to_csv('./Dataset/AmazonProductPrice.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed9ea74",
   "metadata": {},
   "source": [
    "# Extract home page information from best seller headphone pages\n",
    "There are a few product information we can get from a single product item.\n",
    "\n",
    "- ASIN\n",
    "- Product Name\n",
    "- Product Link\n",
    "- Product Rank\n",
    "- Product Price (if any)\n",
    "- Product total reviews\n",
    "\n",
    "I am only looking at the best seller headphone pages so that we can compare other headphones with them.\n",
    "There are only two pages to look at: \n",
    "\n",
    "- 'https://www.amazon.co.uk/Best-Sellers-Electronics-Photo-Headphones-Earphones/zgbs/electronics/4085731/ref=zg_bs_pg_2?_encoding=UTF8&pg=2'\n",
    "- 'https://www.amazon.co.uk/gp/bestsellers/electronics/4085731?ref_=Oct_d_obs_S&pd_rd_w=GN87T&content-id=amzn1.sym.6b376e0b-c3fa-4b95-b5c3-82d50c091b51&pf_rd_p=6b376e0b-c3fa-4b95-b5c3-82d50c091b51&pf_rd_r=04E83P9GTV047MBCJ2D8&pd_rd_wg=CKOyq&pd_rd_r=49c2d810-4b2c-4618-a164-7ed75ea5606a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "057f0688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "best_seller_headphone_homepage = ['https://www.amazon.co.uk/Best-Sellers-Electronics-Photo-Headphones-Earphones/zgbs/electronics/4085731/ref=zg_bs_pg_2?_encoding=UTF8&pg=2',\n",
    "                                 'https://www.amazon.co.uk/gp/bestsellers/electronics/4085731?ref_=Oct_d_obs_S&pd_rd_w=GN87T&content-id=amzn1.sym.6b376e0b-c3fa-4b95-b5c3-82d50c091b51&pf_rd_p=6b376e0b-c3fa-4b95-b5c3-82d50c091b51&pf_rd_r=04E83P9GTV047MBCJ2D8&pd_rd_wg=CKOyq&pd_rd_r=49c2d810-4b2c-4618-a164-7ed75ea5606a']\n",
    "mySoup = get_soup()\n",
    "first_page = mySoup.get_individual_soup(best_seller_headphone_homepage[0],header_attempts = 3, request_attempts = 1)\n",
    "second_page = mySoup.get_individual_soup(best_seller_headphone_homepage[1],header_attempts = 3, request_attempts = 1)\n",
    "\n",
    "best_seller_headphone_homepage_list=[]\n",
    "for i, title in enumerate(second_page.find_all(\"a\", class_ = \"a-link-normal\")):\n",
    "    if i%4 == 0:\n",
    "        Product_Link =\"https://www.amazon.co.uk\"+ title['href']\n",
    "        Product_Link = Product_Link.replace('dp', \"product-reviews\")\n",
    "        Product_Link = re.sub(\"ref.*\",\"\",Product_Link)+ \"ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\"\n",
    "        ASIN = re.search(\"dp/.*/ref\", title['href']).group(0).split(\"/\")[1]\n",
    "    elif i%4==1:\n",
    "        Product_Name = title.get_text() \n",
    "    elif i%4==2:\n",
    "        Product_Rating = title.get_text().split(\" \")[0]\n",
    "        Product_total_reviews = title.get_text().split(\"stars\")[1].strip()\n",
    "    elif i%4==3:\n",
    "        Product_Price = title.get_text()\n",
    "        info_dict = {\"URL\": Product_Link,\n",
    "                     \"Price\":Product_Price,\n",
    "                     \"Rating\":Product_Rating,\n",
    "                     \"ASIN\":ASIN,\n",
    "                     \"Product_Name\":Product_Name,\n",
    "                     \"Total_Reviews\":Product_total_reviews\n",
    "                }\n",
    "        best_seller_headphone_homepage_list.append(info_dict)\n",
    "print(len(best_seller_headphone_homepage_list))\n",
    "with open (\"./Dataset/best_seller_headphone_link.csv\", mode = \"a\") as f:\n",
    "                csv_columns = ['URL', 'Price', 'Rating', 'ASIN', 'Product_Name', 'Total_Reviews']\n",
    "                writer = csv.DictWriter(f, fieldnames=csv_columns)\n",
    "                writer.writeheader()\n",
    "                for prod_info in best_seller_headphone_homepage_list:\n",
    "                    writer.writerow(prod_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f429bbd5",
   "metadata": {},
   "source": [
    "# Text Analysis for the Product Review\n",
    "We will do a few different things here, in general we have:\n",
    "\n",
    "- Text Summarization: this is to summarize all the reviews associated with one product item to 5 maximum sentense. (https://www.activestate.com/blog/how-to-do-text-summarization-with-python/)\n",
    "- Sentiment Analysis to classify product item reviews\n",
    "    - https://realpython.com/sentiment-analysis-python/\n",
    "    - https://www.kaggle.com/code/paoloripamonti/twitter-sentiment-analysis\n",
    "    - https://www.kaggle.com/datasets/shitalkat/amazonearphonesreviews/code\n",
    "    - https://www.kaggle.com/code/foolwuilin/sentiment-analysis-for-3-earphones\n",
    "- To predict the Produtct Price using a range of features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9a2d70",
   "metadata": {},
   "source": [
    "## Understand the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03985059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(213846, 6)\n",
      "238\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASIN</th>\n",
       "      <th>product Name</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Review Rating</th>\n",
       "      <th>Review Body</th>\n",
       "      <th>Review Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B000AJIF4E</td>\n",
       "      <td>Sony MDR-7506/1 Professional Headphone, Black ...</td>\n",
       "      <td>Superb audio, changes how you listen to music</td>\n",
       "      <td>5.0</td>\n",
       "      <td>These are just superb for audio quality. You'l...</td>\n",
       "      <td>Reviewed in the United Kingdom on 1 March 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B000AJIF4E</td>\n",
       "      <td>Sony MDR-7506/1 Professional Headphone, Black ...</td>\n",
       "      <td>Basic build Great sound for the price</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Product used for purely listening purposes mai...</td>\n",
       "      <td>Reviewed in the United Kingdom on 7 January 2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ASIN                                       product Name  \\\n",
       "0  B000AJIF4E  Sony MDR-7506/1 Professional Headphone, Black ...   \n",
       "1  B000AJIF4E  Sony MDR-7506/1 Professional Headphone, Black ...   \n",
       "\n",
       "                                    Review Title Review Rating  \\\n",
       "0  Superb audio, changes how you listen to music           5.0   \n",
       "1          Basic build Great sound for the price           4.0   \n",
       "\n",
       "                                         Review Body  \\\n",
       "0  These are just superb for audio quality. You'l...   \n",
       "1  Product used for purely listening purposes mai...   \n",
       "\n",
       "                                        Review Date  \n",
       "0    Reviewed in the United Kingdom on 1 March 2023  \n",
       "1  Reviewed in the United Kingdom on 7 January 2023  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are total 238 product items in our dataset, with 213846 reviews in total.\n"
     ]
    }
   ],
   "source": [
    "#Load the data\n",
    "import pandas as pd #Used for manipulate dataset\n",
    "total_review = pd.read_parquet(\"./Dataset/AmazonReviews.parquet\")\n",
    "#There one addition header row that we dont need\n",
    "total_review = total_review.loc[~total_review[\"ASIN\"].isin([\"ASIN\"])]\n",
    "print(total_review.shape)\n",
    "print(len(total_review.ASIN.unique()))\n",
    "display(total_review.head(2))\n",
    "print(\"There are total 238 product items in our dataset, with 213846 reviews in total.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec6cf92",
   "metadata": {},
   "source": [
    "### Summarizing Text With SpaCy\n",
    "Our assumption is that a higher-frequency word use implies a more ‘significant’ meaning. This may seem overly simplistic, but this approach often produces surprisingly good results. Based on this assumption, we will do the following steps: (https://www.activestate.com/blog/how-to-do-text-summarization-with-python/)\n",
    "- Look at the use frequency of specific words\n",
    "- Sum the frequencies within each sentence\n",
    "- Rank the sentences based on this sum\n",
    "\n",
    "We’ll use SpaCy to import a pre-trained NLP pipeline to help interpret the grammatical structure of the text. This will allow us to identify the most common words that are often useful to filter out (i.e. STOP_WORDS) as well as the punctuation (i.e. punctuation). We’ll also use the nlargest function to extract a percentage of the most important sentences. Our algorithm will use the following steps:\n",
    "\n",
    "- Tokenize the text with the SpaCy pipeline. This segments the text into words, punctuation, and so on, using grammatical rules specific to the English language. \n",
    "- Count the number of times a word is used (not including stop words or punctuation), then normalize the count. A word that’s used more frequently has a higher normalized count.\n",
    "- Calculate the sum of the normalized count for each sentence.\n",
    "- Extract a percentage of the highest ranked sentences. These serve as our summary.\n",
    "\n",
    "We will above so for each of the product item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "48ba972f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy #used for text summarization\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation\n",
    "from heapq import nlargest\n",
    "# !python -m spacy download en_core_web_sm\n",
    "#Define the function based on the above steps\n",
    "def summarize(text, select_length = 5):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    nlp.max_length = 2226047 # or even higher\n",
    "    doc= nlp(text)\n",
    "    tokens=[token.text for token in doc]\n",
    "    word_frequencies={}\n",
    "    for word in doc:\n",
    "        if word.text.lower() not in list(STOP_WORDS):\n",
    "            if word.text.lower() not in punctuation:\n",
    "                if word.text not in word_frequencies.keys():\n",
    "                    word_frequencies[word.text] = 1\n",
    "                else:\n",
    "                    word_frequencies[word.text] += 1\n",
    "    max_frequency=max(word_frequencies.values())\n",
    "    for word in word_frequencies.keys():\n",
    "        word_frequencies[word]=word_frequencies[word]/max_frequency\n",
    "    sentence_tokens= [sent for sent in doc.sents]\n",
    "    sentence_scores = {}\n",
    "    for sent in sentence_tokens:\n",
    "        for word in sent:\n",
    "            if word.text.lower() in word_frequencies.keys():\n",
    "                if sent not in sentence_scores.keys():                            \n",
    "                    sentence_scores[sent]=word_frequencies[word.text.lower()]\n",
    "                else:\n",
    "                    sentence_scores[sent]+=word_frequencies[word.text.lower()]\n",
    "    summary = {k: v for k, v in sorted(sentence_scores.items(), key=lambda item: item[1], reverse=True)}\n",
    "    return list(summary)[:select_length]\n",
    "\n",
    "ASIN_review = total_review.groupby(['ASIN'])['Review Body'].apply(lambda x: ','.join(x)).reset_index()\n",
    "ASIN_review[\"top 5\"] = ASIN_review['Review Body'].apply(summarize)\n",
    "ASIN_review.to_csv('./Dataset/AmazonReviewsSummarize.csv', index = False)\n",
    "ASIN_review.astype(str).to_parquet('./Dataset/AmazonReviewsSummarize.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "03fddef6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "41c74441",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "1629141051a6d5155c57bd565d322387c500daae99dfac9d1309d017b387cb02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
